{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import web\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from config import *\n",
    "from apphelper.image import union_rbox,adjust_box_to_origin,base64_to_PIL\n",
    "from application import trainTicket,idcard \n",
    "if yoloTextFlag =='keras' or AngleModelFlag=='tf' or ocrFlag=='keras':\n",
    "    if GPU:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPUID)\n",
    "        import tensorflow as tf\n",
    "        from keras import backend as K\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allocator_type = 'BFC'\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 0.3## GPU最大占用量\n",
    "        config.gpu_options.allow_growth = True##GPU是否可动态增加\n",
    "        K.set_session(tf.Session(config=config))\n",
    "        K.get_session().run(tf.global_variables_initializer())\n",
    "    \n",
    "    else:\n",
    "      ##CPU启动\n",
    "      os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n",
    "\n",
    "if yoloTextFlag=='opencv':\n",
    "    scale,maxScale = IMGSIZE\n",
    "    from text.opencv_dnn_detect import text_detect\n",
    "elif yoloTextFlag=='darknet':\n",
    "    scale,maxScale = IMGSIZE\n",
    "    from text.darknet_detect import text_detect\n",
    "elif yoloTextFlag=='keras':\n",
    "    scale,maxScale = IMGSIZE[0],2048\n",
    "    from text.keras_detect import  text_detect\n",
    "else:\n",
    "     print( \"err,text engine in keras\\opencv\\darknet\")\n",
    "     \n",
    "if DETECTANGLE:\n",
    "    from text.opencv_dnn_detect import angle_detect\n",
    "else:\n",
    "    angle_detect = None\n",
    "\n",
    "if ocr_redis:\n",
    "    ##多任务并发识别\n",
    "    from helper.redisbase import redisDataBase\n",
    "    ocr = redisDataBase().put_values\n",
    "else:   \n",
    "    from crnn.keys import alphabetChinese,alphabetEnglish\n",
    "    if ocrFlag=='keras':\n",
    "        from crnn.network_keras import CRNN\n",
    "        if chineseModel:\n",
    "            alphabet = alphabetChinese\n",
    "            if LSTMFLAG:\n",
    "                ocrModel = ocrModelKerasLstm\n",
    "            else:\n",
    "                ocrModel = ocrModelKerasDense\n",
    "        else:\n",
    "            ocrModel = ocrModelKerasEng\n",
    "            alphabet = alphabetEnglish\n",
    "            LSTMFLAG = True\n",
    "            \n",
    "    elif ocrFlag=='torch':\n",
    "        from crnn.network_torch import CRNN\n",
    "        if chineseModel:\n",
    "            alphabet = alphabetChinese\n",
    "            if LSTMFLAG:\n",
    "                ocrModel = ocrModelTorchLstm\n",
    "            else:\n",
    "                ocrModel = ocrModelTorchDense\n",
    "                \n",
    "        else:\n",
    "            ocrModel = ocrModelTorchEng\n",
    "            alphabet = alphabetEnglish\n",
    "            LSTMFLAG = True\n",
    "    elif ocrFlag=='opencv':\n",
    "        from crnn.network_dnn import CRNN\n",
    "        ocrModel = ocrModelOpencv\n",
    "        alphabet = alphabetChinese\n",
    "    else:\n",
    "        print( \"err,ocr engine in keras\\opencv\\darknet\")\n",
    "     \n",
    "    nclass = len(alphabet)+1   \n",
    "    if ocrFlag=='opencv':\n",
    "        crnn = CRNN(alphabet=alphabet)\n",
    "    else:\n",
    "        crnn = CRNN( 32, 1, nclass, 256, leakyRelu=False,lstmFlag=LSTMFLAG,GPU=GPU,alphabet=alphabet)\n",
    "    if os.path.exists(ocrModel):\n",
    "        crnn.load_weights(ocrModel)\n",
    "    else:\n",
    "        print(\"download model or tranform model with tools!\")\n",
    "        \n",
    "    ocr = crnn.predict_job\n",
    "    \n",
    "   \n",
    "from main import TextOcrModel\n",
    "\n",
    "model =  TextOcrModel(ocr,text_detect,angle_detect)\n",
    "from apphelper.image import xy_rotate_box,box_rotate,solve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ft2 = cv2.freetype.createFreeType2()\n",
    "ft2.loadFontData(\"/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc\", 0)\n",
    "\n",
    "def plot_box(img,boxes):\n",
    "    blue = (0, 0, 0) #18\n",
    "    tmp = np.copy(img)\n",
    "    for box in boxes:\n",
    "         cv2.rectangle(tmp, (int(box[0]),int(box[1])), (int(box[2]), int(box[3])), blue, 1) #19\n",
    "    \n",
    "    return Image.fromarray(tmp) \n",
    "\n",
    "def plot_boxes(img,angle, result,color=(0,0,0)):\n",
    "    tmp = np.array(img)\n",
    "    c = color\n",
    "    h,w = img.shape[:2]\n",
    "    thick = int((h + w) / 300)\n",
    "    i = 0\n",
    "    if angle in [90,270]:\n",
    "        imgW,imgH = img.shape[:2]\n",
    "        \n",
    "    else:\n",
    "        imgH,imgW= img.shape[:2]\n",
    "\n",
    "    for line in result:\n",
    "#         print('line:\\n', line)\n",
    "        cx =line['cx']\n",
    "        cy = line['cy']\n",
    "        degree =line['degree']\n",
    "        w  = line['w']\n",
    "        h = line['h']\n",
    "\n",
    "        x1,y1,x2,y2,x3,y3,x4,y4 = xy_rotate_box(cx, cy, w, h, degree/180*np.pi)\n",
    "        \n",
    "        x1,y1,x2,y2,x3,y3,x4,y4 = box_rotate([x1,y1,x2,y2,x3,y3,x4,y4],angle=(360-angle)%360,imgH=imgH,imgW=imgW)\n",
    "        cx  =np.mean([x1,x2,x3,x4])\n",
    "        cy  = np.mean([y1,y2,y3,y4])\n",
    "        cv2.line(tmp,(int(x1),int(y1)),(int(x2),int(y2)),c,1)\n",
    "        cv2.line(tmp,(int(x2),int(y2)),(int(x3),int(y3)),c,1)\n",
    "        cv2.line(tmp,(int(x3),int(y3)),(int(x4),int(y4)),c,1)\n",
    "        cv2.line(tmp,(int(x4),int(y4)),(int(x1),int(y1)),c,1)\n",
    "        mess=str(i)\n",
    "        blurred_tmp = cv2.GaussianBlur(tmp,(3,3), 17)\n",
    "        mask = np.zeros((imgH, imgW, 3), dtype=np.uint8)\n",
    "        cv2.rectangle(mask, (int(x1), int(y1)), (int(x3), int(y3)),\n",
    "                      color=(255, 255, 255), thickness=-1)\n",
    "        tmp = np.where(mask==np.array([255, 255, 255]), blurred_tmp, tmp)\n",
    "        ft2.putText(tmp, line['text'], (int(x1 + w * 0.1), int(y1)), fontHeight=int(h*0.9), color=(255, 51, 51), thickness=-1,\n",
    "                    line_type=cv2.LINE_4, bottomLeftOrigin=False)\n",
    "        # cv2.putText(tmp, line['text'], (int(cx), int(cy - 0.1 * h)), cv2.FONT_HERSHEY_SIMPLEX, h / 30, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "        i+=1\n",
    "    return Image.fromarray(tmp).convert('RGB')\n",
    "\n",
    "\n",
    "def plot_rboxes(img,boxes,color=(0,0,0)):\n",
    "    tmp = np.array(img)\n",
    "    c = color\n",
    "    h,w = img.shape[:2]\n",
    "    thick = int((h + w) / 300)\n",
    "    i = 0\n",
    "\n",
    "\n",
    "    for box in boxes:\n",
    "\n",
    "        x1,y1,x2,y2,x3,y3,x4,y4 = box\n",
    "        \n",
    "        \n",
    "        cx  =np.mean([x1,x2,x3,x4])\n",
    "        cy  = np.mean([y1,y2,y3,y4])\n",
    "        cv2.line(tmp,(int(x1),int(y1)),(int(x2),int(y2)),c,1)\n",
    "        cv2.line(tmp,(int(x2),int(y2)),(int(x3),int(y3)),c,1)\n",
    "        cv2.line(tmp,(int(x3),int(y3)),(int(x4),int(y4)),c,1)\n",
    "        cv2.line(tmp,(int(x4),int(y4)),(int(x1),int(y1)),c,1)\n",
    "        mess=str(i)\n",
    "        cv2.putText(tmp, mess, (int(cx), int(cy)),0, 1e-3 * h, c, thick // 2)\n",
    "        i+=1\n",
    "    return Image.fromarray(tmp).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from PIL import Image\n",
    "p = './test/test_1.png'\n",
    "img = cv2.imread(p)\n",
    "\n",
    "h,w = img.shape[:2]\n",
    "timeTake = time.time()\n",
    "scale=608\n",
    "maxScale=2048\n",
    "\n",
    "result,angle= model.model(img,\n",
    "                                    detectAngle=False,##是否进行文字方向检测\n",
    "                                    scale=scale,\n",
    "                                    maxScale=maxScale,\n",
    "                                    MAX_HORIZONTAL_GAP=80,##字符之间的最大间隔，用于文本行的合并\n",
    "                                    MIN_V_OVERLAPS=0.6,\n",
    "                                    MIN_SIZE_SIM=0.6,\n",
    "                                    TEXT_PROPOSALS_MIN_SCORE=0.1,\n",
    "                                    TEXT_PROPOSALS_NMS_THRESH=0.7,\n",
    "                                    TEXT_LINE_NMS_THRESH = 0.9,##文本行之间测iou值\n",
    "                                     LINE_MIN_SCORE=0.1,                                             \n",
    "                                    leftAdjustAlph=0,##对检测的文本行进行向左延伸\n",
    "                                    rightAdjustAlph=0.1,##对检测的文本行进行向右延伸\n",
    "                                   )\n",
    "        \n",
    "timeTake = time.time()-timeTake\n",
    "\n",
    "print('It take:{}s'.format(timeTake))\n",
    "for line in result:\n",
    "    print(line['text'])\n",
    "    print(line['raw res'])\n",
    "plot_boxes(img,angle, result,color=(0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes,scores  = model.detect_box(img,608,2048)\n",
    "plot_box(img,boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Wrapper for various CTC decoders in SWIG.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import swig_decoders\n",
    "\n",
    "\n",
    "class Scorer(swig_decoders.Scorer):\n",
    "    \"\"\"Wrapper for Scorer.\n",
    "    :param alpha: Parameter associated with language model. Don't use\n",
    "                  language model when alpha = 0.\n",
    "    :type alpha: float\n",
    "    :param beta: Parameter associated with word count. Don't use word\n",
    "                 count when beta = 0.\n",
    "    :type beta: float\n",
    "    :model_path: Path to load language model.\n",
    "    :type model_path: basestring\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha, beta, model_path, vocabulary):\n",
    "        swig_decoders.Scorer.__init__(self, alpha, beta, model_path, vocabulary)\n",
    "\n",
    "\n",
    "def ctc_greedy_decoder(probs_seq, vocabulary):\n",
    "    \"\"\"Wrapper for ctc best path decoder in swig.\n",
    "    :param probs_seq: 2-D list of probability distributions over each time\n",
    "                      step, with each element being a list of normalized\n",
    "                      probabilities over vocabulary and blank.\n",
    "    :type probs_seq: 2-D list\n",
    "    :param vocabulary: Vocabulary list.\n",
    "    :type vocabulary: list\n",
    "    :return: Decoding result string.\n",
    "    :rtype: basestring\n",
    "    \"\"\"\n",
    "    result = swig_decoders.ctc_greedy_decoder(probs_seq.tolist(), vocabulary)\n",
    "    return result\n",
    "\n",
    "\n",
    "def ctc_beam_search_decoder(probs_seq,\n",
    "                            vocabulary,\n",
    "                            beam_size,\n",
    "                            cutoff_prob=1.0,\n",
    "                            cutoff_top_n=40,\n",
    "                            ext_scoring_func=None):\n",
    "    \"\"\"Wrapper for the CTC Beam Search Decoder.\n",
    "    :param probs_seq: 2-D list of probability distributions over each time\n",
    "                      step, with each element being a list of normalized\n",
    "                      probabilities over vocabulary and blank.\n",
    "    :type probs_seq: 2-D list\n",
    "    :param vocabulary: Vocabulary list.\n",
    "    :type vocabulary: list\n",
    "    :param beam_size: Width for beam search.\n",
    "    :type beam_size: int\n",
    "    :param cutoff_prob: Cutoff probability in pruning,\n",
    "                        default 1.0, no pruning.\n",
    "    :type cutoff_prob: float\n",
    "    :param cutoff_top_n: Cutoff number in pruning, only top cutoff_top_n\n",
    "                         characters with highest probs in vocabulary will be\n",
    "                         used in beam search, default 40.\n",
    "    :type cutoff_top_n: int\n",
    "    :param ext_scoring_func: External scoring function for\n",
    "                             partially decoded sentence, e.g. word count\n",
    "                             or language model.\n",
    "    :type external_scoring_func: callable\n",
    "    :return: List of tuples of log probability and sentence as decoding\n",
    "             results, in descending order of the probability.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    beam_results = swig_decoders.ctc_beam_search_decoder(\n",
    "        probs_seq.tolist(), vocabulary, beam_size, cutoff_prob, cutoff_top_n,\n",
    "        ext_scoring_func)\n",
    "    beam_results = [(res[0], res[1]) for res in beam_results]\n",
    "    return beam_results\n",
    "\n",
    "\n",
    "def ctc_beam_search_decoder_batch(probs_split,\n",
    "                                  vocabulary,\n",
    "                                  beam_size,\n",
    "                                  num_processes,\n",
    "                                  cutoff_prob=1.0,\n",
    "                                  cutoff_top_n=40,\n",
    "                                  ext_scoring_func=None):\n",
    "    \"\"\"Wrapper for the batched CTC beam search decoder.\n",
    "    :param probs_seq: 3-D list with each element as an instance of 2-D list\n",
    "                      of probabilities used by ctc_beam_search_decoder().\n",
    "    :type probs_seq: 3-D list\n",
    "    :param vocabulary: Vocabulary list.\n",
    "    :type vocabulary: list\n",
    "    :param beam_size: Width for beam search.\n",
    "    :type beam_size: int\n",
    "    :param num_processes: Number of parallel processes.\n",
    "    :type num_processes: int\n",
    "    :param cutoff_prob: Cutoff probability in vocabulary pruning,\n",
    "                        default 1.0, no pruning.\n",
    "    :type cutoff_prob: float\n",
    "    :param cutoff_top_n: Cutoff number in pruning, only top cutoff_top_n\n",
    "                         characters with highest probs in vocabulary will be\n",
    "                         used in beam search, default 40.\n",
    "    :type cutoff_top_n: int\n",
    "    :param num_processes: Number of parallel processes.\n",
    "    :type num_processes: int\n",
    "    :param ext_scoring_func: External scoring function for\n",
    "                             partially decoded sentence, e.g. word count\n",
    "                             or language model.\n",
    "    :type external_scoring_function: callable\n",
    "    :return: List of tuples of log probability and sentence as decoding\n",
    "             results, in descending order of the probability.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    # probs_split = [probs_seq.tolist() for probs_seq in probs_split]\n",
    "    probs_split = probs_split.tolist()\n",
    "\n",
    "    batch_beam_results = swig_decoders.ctc_beam_search_decoder_batch(\n",
    "        probs_split, vocabulary, beam_size, num_processes, cutoff_prob,\n",
    "        cutoff_top_n, ext_scoring_func)\n",
    "    batch_beam_results = [\n",
    "        [(res[0], res[1]) for res in beam_results]\n",
    "        for beam_results in batch_beam_results\n",
    "    ]\n",
    "    return batch_beam_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_list = [c for c in alphabet]\n",
    "scorer = Scorer(alpha=2.5, beta=0.3, model_path='./models/zh_giga.no_cna_cmn.prune01244.klm',\n",
    "                vocabulary=alphabet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************** \n",
      "DEBUG: len(boxes): 563 , scores: (563,) , boxes: (563, 4)\n",
      "It take:0.8277773857116699s\n",
      "T4109661\n",
      "\n",
      "T---------------4------1---0-----------9-----------6-----------6----1--\n",
      "[h2F一二7/7---.c44-444081-11089972338..9909999997.16656677777...6-6011]11\n",
      "Ju3TF字T7TF0.-e王9A中a-..4l209908932831117-gggggg9g71千-5763333716王57477770\n",
      "Ig97j一/「F7Sc:一干qq9g11c2I32868787王金7:28gHHH7777cc.0王0BBB6448,71千子G13l-3.\n",
      "\n",
      "torch.Size([1, 71, 5530])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from PIL import Image\n",
    "p = './test/HW1.PNG'\n",
    "img = cv2.imread(p)\n",
    "\n",
    "h,w = img.shape[:2]\n",
    "timeTake = time.time()\n",
    "scale=608\n",
    "maxScale=2048\n",
    "\n",
    "result,angle= model.model(img,\n",
    "                                    detectAngle=False,##是否进行文字方向检测\n",
    "                                    scale=scale,\n",
    "                                    maxScale=maxScale,\n",
    "                                    MAX_HORIZONTAL_GAP=80,##字符之间的最大间隔，用于文本行的合并\n",
    "                                    MIN_V_OVERLAPS=0.6,\n",
    "                                    MIN_SIZE_SIM=0.6,\n",
    "                                    TEXT_PROPOSALS_MIN_SCORE=0.1,\n",
    "                                    TEXT_PROPOSALS_NMS_THRESH=0.7,\n",
    "                                    TEXT_LINE_NMS_THRESH = 0.9,##文本行之间测iou值\n",
    "                                     LINE_MIN_SCORE=0.1,                                             \n",
    "                                    leftAdjustAlph=0,##对检测的文本行进行向左延伸\n",
    "                                    rightAdjustAlph=0.1,##对检测的文本行进行向右延伸\n",
    "                                   )\n",
    "        \n",
    "timeTake = time.time()-timeTake\n",
    "\n",
    "print('It take:{}s'.format(timeTake))\n",
    "for line in result:\n",
    "    print(line['text'], flush=True)\n",
    "    print(line['raw res'], flush=True)\n",
    "    print(line['raw preds'].shape, flush=True)\n",
    "    beam_search_results = ctc_beam_search_decoder_batch(\n",
    "            probs_split=line['raw preds'],\n",
    "            vocabulary=alphabet_list,\n",
    "            beam_size=500,\n",
    "            num_processes=1,\n",
    "            ext_scoring_func=scorer,\n",
    "            cutoff_prob=1.0,\n",
    "            cutoff_top_n=40)\n",
    "    print(beam_search_results, flush=True)\n",
    "plot_boxes(img,angle, result,color=(0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
